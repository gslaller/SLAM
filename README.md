# SLAM: ü§ñüó∫Ô∏è Simultaneous Localisation and Mapping 

This project is a Python implementation of a neural network-based simultaneous localization and mapping (NN-SLAM) algorithm that takes a video as input and estimates the camera position and depth map at each frame. The algorithm uses convolutional neural networks (CNNs) with a U-Net architecture and the PyTorch framework to address the three main challenges of classical SLAM: camera pose estimation, depth map creation, and loop closure detection.

1. **camera pose estimation/visual odometry:** estimation component of the algorithm leverages the latent vector generated by a CNN to determine the camera's position and orientation relative to the previous frame. This is achieved by identifying distinctive features in the camera's images and using them to perform triangulation through a process known as epipolar geometry.

2. **depth map/monocular depth estimation:** generation component uses a U-Net architecture to provide a latent vector for each pixel in the image. These vectors is then used in a gradient descent procedure to find matching points between different frames. The resulting depth map is generated by combining delta on the principle plane between frame with the visual odometry(given that the scene is static).

3. **Loop closure:** (Similar to camera pose estimation) detection component of the algorithm uses the latent vector of an image frame generated by the CNN to detect when the device has returned to a previously visited location and update the map accordingly. This helps to correct for drift and variations in the viewing angle.

## Installation üì¶‚¨áÔ∏è

<details>
  <summary>Local Install üíª</summary>
  
#### Libraries to be installed
  
1. pytorch
2. opencv-python
        
#### bash
```
python -m install -r requirements.txt
```
</details>

<details>
  <summary>With docker üê≥</summary>
  
### Installation
  
1. Docker --version == xx

### Script
```bash
docker run -d -p 8088:8088 gslaller/SLAM:v1
```
</details>

## Usage

- To run the SLAM algorithm on a video file, use the following command:  
        ```bash
        python slam.py --video <video_file> [--output <output_file>]
        ```

- With docker use `localhost:8088` in the local browser.

